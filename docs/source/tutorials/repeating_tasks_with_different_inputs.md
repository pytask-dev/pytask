# Repeating tasks with different inputs

You want to define a task which should be repeated over a range of inputs? Loop over
your task function!

:::{important}
Before v0.2.0, pytask supported only one approach to repeat tasks. It is called also
called parametrizations and similarly to pytest it is using a
{func}`@pytask.mark.parametrize <_pytask.parametrize.parametrize>` decorator. If you
want to know more about it, you can find it
{doc}`here <../how_to_guides/repeating_tasks_with_different_inputs_the_pytest_way>`.

Here you find the new and preferred approach.
:::

## An example

We reuse the task from the previous {doc}`tutorial <write_a_task>` which generates
random data and repeat the same operation over a number of seeds to receive multiple,
reproducible samples.

Apply the {func}`@pytask.mark.task <_pytask.task_utils.task>` decorator, loop over the
function and supply different seeds and output paths as default arguments of the
function.

```python
import numpy as np
import pytask


for i in range(10):

    @pytask.mark.task
    def task_create_random_data(produces=f"data_{i}.pkl", seed=i):
        rng = np.random.default_rng(seed)
        ...
```

Executing pytask gives you this:

```{image} /_static/images/repeating-tasks.svg
```

## `depends_on` and `produces`

You can also use decorators to supply values to the function.

To specify a dependency which is the same for all iterations, add it with
{func}`@pytask.mark.depends_on <_pytask.collect_utils.depends_on>`. And add a product
with {func}`@pytask.mark.produces <_pytask.collect_utils.produces>`

```python
for i in range(10):

    @pytask.mark.task
    @pytask.mark.depends_on(SRC / "common_dependency.file")
    @pytask.mark.produces(f"data_{i}.pkl")
    def task_create_random_data(produces, seed=i):
        rng = np.random.default_rng(seed)
        ...
```

(how-to-repeat-a-task-with-different-inputs-the-id)=

## The id

Every task has a unique id which can be used to {doc}`select it <selecting_tasks>`.
The normal id combines the path to the module where the task is defined, a double colon,
and the name of the task function. Here is an example.

```
../task_data_preparation.py::task_create_random_data
```

This behavior would produce duplicate ids for parametrized tasks. By default,
auto-generated ids are used which are explained {ref}`here <auto-generated-ids>`.

More powerful are user-defined ids.

(ids)=

### User-defined ids

The {func}`@pytask.mark.task <_pytask.task_utils.task>` decorator has an `id` keyword
which allows the user to set the a special name for the iteration.

```python
for seed, id_ in [(0, "first"), (1, "second")]:

    @pytask.mark.task(id=id_)
    def task_create_random_data(seed=i, produces=f"out_{i}.txt"):
        ...
```

produces these ids

```
task_data_preparation.py::task_create_random_data[first]
task_data_preparation.py::task_create_random_data[second]
```

## Complex example

Parametrizations are becoming more complex quickly. Often, you need to supply many
arguments and ids to tasks.

To organize your ids and arguments use nested dictionaries where keys are ids and values
are dictionaries mapping from argument names to values.

```python
ID_TO_KWARGS = {
    "first": {
        "seed": 0,
        "produces": "data_0.pkl",
    },
    "second": {
        "seed": 1,
        "produces": "data_1.pkl",
    },
}
```

The parametrization becomes

```python
for id_, kwargs in ID_TO_KWARGS.items():

    @pytask.mark.task(id=id_)
    def task_create_random_data(seed=kwargs["seed"], produces=kwargs["produces"]):
        ...
```

Unpacking all the arguments can become tedious. Use instead the `kwargs` argument of the
{func}`@pytask.mark.task <_pytask.task_utils.task>` decorator to pass keyword arguments
to the task.

```python
for id_, kwargs in ID_TO_KWARGS.items():

    @pytask.mark.task(id=id_, kwargs=kwargs)
    def task_create_random_data(seed, produces):
        ...
```

As a last step to organize our code even more, we can write a function which creates
`ID_TO_KWARGS`. You can hide the creation of input and output paths and other arguments
in this function.

```python
def create_parametrization():
    id_to_kwargs = {}
    for i, id_ in enumerate(["first", "second"]):
        id_to_kwargs[id_] = {"produces": f"out_{i}.txt"}

    return id_to_kwargs


ID_TO_KWARGS = create_parametrization()


for id_, kwargs in ID_TO_KWARGS.items():

    @pytask.mark.task(id=id_, kwargs=kwargs)
    def task_create_random_data(i, produces):
        ...
```

The
{doc}`best-practices guide on parametrizations <../how_to_guides/bp_parametrizations>`
goes into even more detail on how to scale parametrizations.


## A warning on globals

The following example serves as a warning against using globals in your task functions.
And, it is also kind of riddle. Maybe you can spot the problem.

You won't run into these problems if you strictly use the interfaces explained below.

Look at this repeated task which runs three times and each time creates a different text
file with some content.

```python
import pytask
from pathlib import Path


for i in range(3):

    @pytask.mark.task
    @pytask.mark.produces(f"out_{i}.txt")
    def task_example():
        path_of_module_folder = Path(__file__).parent
        path_to_product = path_of_module_folder.joinpath(f"out_{i}.txt")
        path_to_product.write_text("I use running globals. How funny.")
```

If you would execute these tasks, pytask would collect three tasks as usually. But, only
the last task for `i = 2` would succeed. The other tasks would fail, both saying their
text files `out_0.txt` and `out_1.txt` have not been created.

```{dropdown} Explanation

The problem with this example is the running variable `i` which is a global variable
with changing state.

When the task module is imported, all three task functions are created and the
`@pytask.mark.produces` decorator receives the correct reference to the produced file.

But when the task is executed, the value of the variable `i = 2` which is the last state
of `i` after the loop has completed.

So, all three tasks are creating the same file `out_3.txt`.

The solution is to use the intended channels to pass variables to tasks which are the
`kwargs` argument of `@pytask.mark.task` or the default value in the function signature.

```python
for i in range(3):

    @pytask.mark.task(kwargs={"i": i})
    @pytask.mark.produces(f"out_{i}.txt")
    def task_example(i):
        ...

    # or

    @pytask.mark.task
    @pytask.mark.produces(f"out_{i}.txt")
    def task_example(i=i):
        ...
```
